{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae import Sae\n",
    "\n",
    "# load two saes, which is in the first two layers.\n",
    "saes = {\n",
    "    \"layers.0\": Sae.load_from_hub(\n",
    "        \"EleutherAI/sae-pythia-70m-deduped-32k\", hookpoint=\"layers.0\"\n",
    "    ),\n",
    "    \"layers.1\": Sae.load_from_hub(\n",
    "        \"EleutherAI/sae-pythia-70m-deduped-32k\", hookpoint=\"layers.1\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\n",
    "    \"EleutherAI/the_pile_deduplicated\", split=\"train\", streaming=True\n",
    ")\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m-deduped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Process parameters\n",
    "batch_size = 4\n",
    "max_batches = 5\n",
    "max_samples = batch_size * max_batches\n",
    "\n",
    "# Initialize counters and tracking variables\n",
    "common_indices_layer_1 = Counter()  # Track activations for layer 1\n",
    "batch_texts = []\n",
    "total_samples_processed = 0\n",
    "\n",
    "# A list to store latent activations for further processing\n",
    "all_layer_0_latent_acts = []  # Store all data from layer.0\n",
    "all_layer_1_latent_acts = []  # Store all data from layer.1\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Process dataset with progress bar\n",
    "for sample in tqdm(dataset, total=max_samples, desc=\"Processing samples\"):\n",
    "    batch_texts.append(sample[\"text\"])\n",
    "    total_samples_processed += 1\n",
    "\n",
    "    # Process in batches\n",
    "    if len(batch_texts) == batch_size:\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "        latent_acts_batch = []\n",
    "\n",
    "        # Loop through layers, update for layer 1 and collect data for layer 0\n",
    "        for layer_name, (sae, hidden_state) in zip(\n",
    "            saes.keys(), zip(saes.values(), outputs.hidden_states)\n",
    "        ):\n",
    "            latent_acts = sae.encode(hidden_state)  # Encode the hidden state using SAE\n",
    "\n",
    "            if layer_name == \"layers.1\":  # Focus on activations for layer 1\n",
    "                common_indices_layer_1.update(\n",
    "                    latent_acts.top_indices.flatten().tolist()\n",
    "                )\n",
    "                all_layer_1_latent_acts.append(\n",
    "                    latent_acts\n",
    "                )  # Collect data for future reference\n",
    "\n",
    "            if layer_name == \"layers.0\":  # Collect layer.0 activations\n",
    "                all_layer_0_latent_acts.append(latent_acts)\n",
    "\n",
    "            latent_acts_batch.append(latent_acts)\n",
    "\n",
    "        # Clear batch after processing\n",
    "        batch_texts = []\n",
    "\n",
    "    if total_samples_processed >= max_samples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flattened_top_acts_indices(layer_acts):\n",
    "    all_acts, all_indices = [], []\n",
    "\n",
    "    for enc_out in layer_acts:\n",
    "        acts_list = enc_out.top_acts.tolist()\n",
    "        indices_list = enc_out.top_indices.tolist()\n",
    "\n",
    "        for acts, indices in zip(acts_list, indices_list):\n",
    "            for act, ind in zip(acts, indices):\n",
    "                all_acts.append(act)\n",
    "                all_indices.append(ind)\n",
    "\n",
    "    return all_acts, all_indices\n",
    "\n",
    "\n",
    "def filter_by_neuron(\n",
    "    front_top_acts, front_top_indices, back_top_acts, back_top_indices, target_neuron\n",
    "):\n",
    "    filtered_front_acts = []  # To store the filtered top_acts for the front layer\n",
    "    filtered_front_indices = []  # To store the filtered top_indices for the front layer\n",
    "    filtered_back_acts = []  # To store the filtered top_acts for the back layer\n",
    "    filtered_back_indices = []  # To store the filtered top_indices for the back layer\n",
    "\n",
    "    # Iterate over each token's activations and indices in the back layer\n",
    "    for i, (token_top_acts_back, token_top_indices_back) in enumerate(\n",
    "        zip(back_top_acts, back_top_indices)\n",
    "    ):\n",
    "        # Check if the target neuron is in the top indices for the token in the back layer\n",
    "        if target_neuron in token_top_indices_back:\n",
    "            # If the neuron is activated, keep the corresponding token data from both layers\n",
    "            filtered_back_acts.append(token_top_acts_back)\n",
    "            filtered_back_indices.append(token_top_indices_back)\n",
    "            filtered_front_acts.append(\n",
    "                front_top_acts[i]\n",
    "            )  # Corresponding data from the front layer\n",
    "            filtered_front_indices.append(\n",
    "                front_top_indices[i]\n",
    "            )  # Corresponding data from the front layer\n",
    "\n",
    "    return (\n",
    "        filtered_front_acts,\n",
    "        filtered_front_indices,\n",
    "        filtered_back_acts,\n",
    "        filtered_back_indices,\n",
    "    )\n",
    "\n",
    "\n",
    "def update_acts(front_acts, front_indices):\n",
    "    unified_indices = sorted({ind for indices in front_indices for ind in indices})\n",
    "\n",
    "    updated_acts = []\n",
    "    for acts, indices in zip(front_acts, front_indices):\n",
    "        idx_to_act = dict(zip(indices, acts))\n",
    "        updated_acts.append([idx_to_act.get(neuron, 0) for neuron in unified_indices])\n",
    "\n",
    "    return updated_acts, unified_indices\n",
    "\n",
    "\n",
    "def extract_Y(back_acts, back_indices, target_neuron):\n",
    "    return [\n",
    "        acts[indices.index(target_neuron)]\n",
    "        for acts, indices in zip(back_acts, back_indices)\n",
    "        if target_neuron in indices\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(common_indices_layer_1)\n",
    "target_neuron = common_indices_layer_1.most_common(1)[0][\n",
    "    0\n",
    "]  # Get the most frequent neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_0_top_acts_list, layer_0_top_indices_list = extract_flattened_top_acts_indices(\n",
    "    all_layer_0_latent_acts\n",
    ")\n",
    "layer_1_top_acts_list, layer_1_top_indices_list = extract_flattened_top_acts_indices(\n",
    "    all_layer_1_latent_acts\n",
    ")\n",
    "\n",
    "# Use the updated function names with the correct variable names from earlier in the code\n",
    "filtered_0_acts, filtered_0_indices, filtered_1_acts, filtered_1_indices = (\n",
    "    filter_by_neuron(\n",
    "        layer_0_top_acts_list,\n",
    "        layer_0_top_indices_list,\n",
    "        layer_1_top_acts_list,\n",
    "        layer_1_top_indices_list,\n",
    "        target_neuron,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update activations for the front layer (layer 0)\n",
    "updated_0_acts, unified_indices_list = update_acts(filtered_0_acts, filtered_0_indices)\n",
    "\n",
    "# X represents updated activations for the front layer (layer 0), Y represents activations from the back layer (layer 1)\n",
    "X = updated_0_acts\n",
    "Y = extract_Y(filtered_1_acts, filtered_1_indices, target_neuron)\n",
    "\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysr import PySRRegressor\n",
    "\n",
    "# Initialize the symbolic regression model\n",
    "model = PySRRegressor(\n",
    "    niterations=100,  # Increase if necessary\n",
    "    binary_operators=[\"+\", \"-\", \"*\", \"/\"],  # Operations to use\n",
    "    unary_operators=[\"cos\", \"sin\", \"exp\", \"log\"],\n",
    ")\n",
    "\n",
    "# Train the model on the top activations and their corresponding top indices\n",
    "model.fit(X, Y)\n",
    "\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
